{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis_rnn.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "JhfmSB4kcQDV",
        "ZVGwqM_XFZIq",
        "RITdTeFH3HIr"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig1HGm_sXvHx"
      },
      "source": [
        "# Twitter Sentiment Analysis - Recurrent Neural Networks \n",
        "## <div> Vassilis Panagakis </div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQ0xV4tFJZTI",
        "outputId": "fa07bd18-d151-4a74-b792-48c77f9f3170"
      },
      "source": [
        "!pip install d2l==0.15.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting d2l==0.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/4f/d169ebbd3c686b6ade9cba78fa2730ba5583048b901cd3b2cf01b28ea651/d2l-0.15.0-py3-none-any.whl (59kB)\n",
            "\r\u001b[K     |█████▌                          | 10kB 24.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 20kB 32.5MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 30kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 40kB 17.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 51kB 15.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from d2l==0.15.0) (3.2.2)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from d2l==0.15.0) (1.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from d2l==0.15.0) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from d2l==0.15.0) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==0.15.0) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==0.15.0) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==0.15.0) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==0.15.0) (2.4.7)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.15.0) (4.10.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.15.0) (5.6.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.15.0) (5.2.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.15.0) (5.0.2)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.15.0) (5.3.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.15.0) (7.6.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->d2l==0.15.0) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->d2l==0.15.0) (1.15.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l==0.15.0) (5.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l==0.15.0) (5.3.5)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l==0.15.0) (4.3.3)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l==0.15.0) (5.1.1)\n",
            "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.15.0) (5.1.2)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.15.0) (0.4.4)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.15.0) (2.11.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.15.0) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.15.0) (0.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.15.0) (1.4.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.15.0) (0.6.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.15.0) (3.3.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.15.0) (2.6.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.15.0) (4.7.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->d2l==0.15.0) (1.0.18)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->d2l==0.15.0) (1.9.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->d2l==0.15.0) (0.2.0)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->d2l==0.15.0) (22.0.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.15.0) (1.5.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.15.0) (0.9.2)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l==0.15.0) (1.0.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l==0.15.0) (3.5.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.15.0) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.15.0) (53.0.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.15.0) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.15.0) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.15.0) (0.8.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.4->nbconvert->jupyter->d2l==0.15.0) (2.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.4->nbconvert->jupyter->d2l==0.15.0) (1.1.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->d2l==0.15.0) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->d2l==0.15.0) (20.9)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->d2l==0.15.0) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->d2l==0.15.0) (0.7.0)\n",
            "Installing collected packages: d2l\n",
            "Successfully installed d2l-0.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3VQYcefW8Hf"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import re\n",
        "import warnings\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "warnings.filterwarnings('ignore')  "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sStnn3cnXAOM"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyzcY9_IXCal",
        "outputId": "a2aeeb30-bddc-4e87-80cd-cc685ce23b69"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LM1FQO7XNK6"
      },
      "source": [
        "#### Create a dataframe from SentimentTweets.csv file data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z54N_yxEXG2r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7feccf4a-f1f8-4ff3-bceb-8dcc218c86e9"
      },
      "source": [
        "df=pd.read_csv('gdrive/My Drive/Colab Notebooks/SentimentTweets.csv', usecols=['target','id','date','flag','user','text'])\n",
        "\n",
        "df.head()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2249621587</td>\n",
              "      <td>Fri Jun 19 22:41:08 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>sukumarpant</td>\n",
              "      <td>#brokenpromises...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>2059003515</td>\n",
              "      <td>Sat Jun 06 16:03:21 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>MTMSparrow</td>\n",
              "      <td>David Carradine  so sad. Thai's law not sure i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>2017466467</td>\n",
              "      <td>Wed Jun 03 08:26:14 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>itsmemcee</td>\n",
              "      <td>A @ 415 B @ 425. Tell your bro i say congrats!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2186457254</td>\n",
              "      <td>Mon Jun 15 18:52:04 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>jdfreivald</td>\n",
              "      <td>@littlefluffycat  Indeed.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2064458395</td>\n",
              "      <td>Sun Jun 07 06:19:20 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>CrazyHan</td>\n",
              "      <td>Completed Race 4 Life in 58mins with girlies f...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target  ...                                               text\n",
              "0       0  ...                                #brokenpromises... \n",
              "1       0  ...  David Carradine  so sad. Thai's law not sure i...\n",
              "2       4  ...    A @ 415 B @ 425. Tell your bro i say congrats! \n",
              "3       4  ...                          @littlefluffycat  Indeed.\n",
              "4       4  ...  Completed Race 4 Life in 58mins with girlies f...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "um-sOo0R1RRt",
        "outputId": "0af1b036-b904-408c-f789-cd1d2c7a50aa"
      },
      "source": [
        "df.drop(columns=['id', 'date', 'flag', 'user'], axis=1, inplace=True) #drop useless columns\r\n",
        "\r\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>#brokenpromises...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>David Carradine  so sad. Thai's law not sure i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>A @ 415 B @ 425. Tell your bro i say congrats!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>@littlefluffycat  Indeed.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Completed Race 4 Life in 58mins with girlies f...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target                                               text\n",
              "0       0                                #brokenpromises... \n",
              "1       0  David Carradine  so sad. Thai's law not sure i...\n",
              "2       4    A @ 415 B @ 425. Tell your bro i say congrats! \n",
              "3       4                          @littlefluffycat  Indeed.\n",
              "4       4  Completed Race 4 Life in 58mins with girlies f..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rxc3Nze1ToO"
      },
      "source": [
        "# split 'target' and 'text' columns \r\n",
        "X = df[['text']]\r\n",
        "y = df[['target']]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOH8oV7b1Wtk"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "# get train and test dataframes \r\n",
        "train_X, test_X, train_Y, test_Y = train_test_split(X, y, test_size=0.2, stratify=df['target'], random_state = 42)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qt2539dXho5"
      },
      "source": [
        "#### Display train and test sets after split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "EM1VLqxVXgI1",
        "outputId": "068c9b92-3ff5-4ce6-8f27-07c1ea33b4a2"
      },
      "source": [
        "train_X.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>492660</th>\n",
              "      <td>The respected journalist @robfahey just tried ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>858754</th>\n",
              "      <td>@maggienash  Thanks, Maggie.  I'm still bouncing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>746070</th>\n",
              "      <td>@do0dlebugdebz not now,but will be if you're o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>885531</th>\n",
              "      <td>@Pure798 yea that works...ughh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>806384</th>\n",
              "      <td>@melapoo lol Cool. I keep getting the weird on...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text\n",
              "492660  The respected journalist @robfahey just tried ...\n",
              "858754  @maggienash  Thanks, Maggie.  I'm still bouncing \n",
              "746070  @do0dlebugdebz not now,but will be if you're o...\n",
              "885531                    @Pure798 yea that works...ughh \n",
              "806384  @melapoo lol Cool. I keep getting the weird on..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "OBaNuTQZXksQ",
        "outputId": "58eefcf9-e784-4fb1-aabf-0cf4fc689b79"
      },
      "source": [
        "test_X.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>220479</th>\n",
              "      <td>...... fuck you soderling. fuck you. this has ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>840623</th>\n",
              "      <td>OK next step - today I learn to twitter from m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>772674</th>\n",
              "      <td>trying to upload a picture and loves how twitt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1037193</th>\n",
              "      <td>@addictedtonye Get 100 followers a day using w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>971656</th>\n",
              "      <td>@AmeliaBt It sure is..</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      text\n",
              "220479   ...... fuck you soderling. fuck you. this has ...\n",
              "840623   OK next step - today I learn to twitter from m...\n",
              "772674   trying to upload a picture and loves how twitt...\n",
              "1037193  @addictedtonye Get 100 followers a day using w...\n",
              "971656                             @AmeliaBt It sure is.. "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ClyD5k4Xl61"
      },
      "source": [
        "## Labels Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6o-BhRXXnlJ"
      },
      "source": [
        "# replace 4 with 1 to create binary labels\n",
        "train_Y = train_Y.replace(4,1)\n",
        "test_Y = test_Y.replace(4,1)\n",
        "\n",
        "# create numpy arrays for sets' labels\n",
        "train_y = np.asarray(train_Y['target'].tolist()) \n",
        "test_y = np.asarray(test_Y['target'].tolist())\n",
        "\n",
        "# covert numpy arrays to torch tensors\n",
        "train_y, test_y = map(torch.tensor, (train_y, test_y))\n",
        "# covert tensors data to float\n",
        "train_y, test_y = train_y.float(), test_y.float()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzDrAI8xXpzc"
      },
      "source": [
        "## Data Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhfmSB4kcQDV"
      },
      "source": [
        "#### Load cleansed data from csv\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoFIMphscMsR"
      },
      "source": [
        "# restore processed data\n",
        "train_X = pd.read_csv('gdrive/My Drive/Colab Notebooks/CleanedTrain.csv', usecols=['text','processedText'])\n",
        "test_X = pd.read_csv('gdrive/My Drive/Colab Notebooks/CleanedTest.csv', usecols=['text','processedText'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8UMJDrgchTW"
      },
      "source": [
        "### Cleanse data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtrcZJSWXsb7"
      },
      "source": [
        "# function that removes all @mentions, links and non alphabetic strings \n",
        "def clean_content(text):\n",
        "    \n",
        "    text = re.sub(r'@[A-Za-z0-9_]+', '', text) # remove text with @ prefix\n",
        "    text = re.sub(r'http\\S+', '', text) # remove text with http prefix (links)  \n",
        "    text = re.sub(r'www\\S+', '', text) # remove text with www prefix (links)\n",
        "    text = re.sub(r'\\\\\\w+', '', str(text)) # remove text after backslash\n",
        "    text = re.sub(r'\\b\\w{1,2}\\b', '', text) # remove text containing 2 or less characters\n",
        "    \n",
        "    text =  ''.join(ch for ch in text if ch.isalpha() or ch == ' ')\n",
        "    \n",
        "    text = text.lower() # convert text into lowercase\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRZXeA2nXt8L"
      },
      "source": [
        "# create a column for each set containing the processed text data\n",
        "for index, row in train_X.iterrows():\n",
        "    train_X.loc[index,'processedText'] = clean_content(train_X.loc[index,'text'])\n",
        "\n",
        "for index, row in test_X.iterrows():\n",
        "    test_X.loc[index,'processedText'] = clean_content(test_X.loc[index,'text'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt5LUmFqXwzV"
      },
      "source": [
        "#### Display train and test sets after text cleansing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "YPZLdglyXvZh",
        "outputId": "a5951472-16ec-4f81-f299-e01886ec0e8e"
      },
      "source": [
        "train_X.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>processedText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>492660</th>\n",
              "      <td>The respected journalist @robfahey just tried ...</td>\n",
              "      <td>the respected journalist  just tried  have sex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>858754</th>\n",
              "      <td>@maggienash  Thanks, Maggie.  I'm still bouncing</td>\n",
              "      <td>thanks maggie   still bouncing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>746070</th>\n",
              "      <td>@do0dlebugdebz not now,but will be if you're o...</td>\n",
              "      <td>not nowbut will   you    just sounded like da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>885531</th>\n",
              "      <td>@Pure798 yea that works...ughh</td>\n",
              "      <td>yea that worksughh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>806384</th>\n",
              "      <td>@melapoo lol Cool. I keep getting the weird on...</td>\n",
              "      <td>lol cool  keep getting the weird ones  got th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text                                      processedText\n",
              "492660  The respected journalist @robfahey just tried ...  the respected journalist  just tried  have sex...\n",
              "858754  @maggienash  Thanks, Maggie.  I'm still bouncing                     thanks maggie   still bouncing \n",
              "746070  @do0dlebugdebz not now,but will be if you're o...   not nowbut will   you    just sounded like da...\n",
              "885531                    @Pure798 yea that works...ughh                                 yea that worksughh \n",
              "806384  @melapoo lol Cool. I keep getting the weird on...   lol cool  keep getting the weird ones  got th..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "8_dyGR4IXzTG",
        "outputId": "f805600e-1070-428b-e3de-c7be7c6da98a"
      },
      "source": [
        "test_X.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>processedText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>220479</th>\n",
              "      <td>...... fuck you soderling. fuck you. this has ...</td>\n",
              "      <td>fuck you soderling fuck you this has    night...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>840623</th>\n",
              "      <td>OK next step - today I learn to twitter from m...</td>\n",
              "      <td>next step  today  learn  twitter from  phone ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>772674</th>\n",
              "      <td>trying to upload a picture and loves how twitt...</td>\n",
              "      <td>trying  upload  picture and loves how twitter ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1037193</th>\n",
              "      <td>@addictedtonye Get 100 followers a day using w...</td>\n",
              "      <td>get  followers  day using  once you add every...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>971656</th>\n",
              "      <td>@AmeliaBt It sure is..</td>\n",
              "      <td>sure</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      text                                      processedText\n",
              "220479   ...... fuck you soderling. fuck you. this has ...   fuck you soderling fuck you this has    night...\n",
              "840623   OK next step - today I learn to twitter from m...   next step  today  learn  twitter from  phone ...\n",
              "772674   trying to upload a picture and loves how twitt...  trying  upload  picture and loves how twitter ...\n",
              "1037193  @addictedtonye Get 100 followers a day using w...   get  followers  day using  once you add every...\n",
              "971656                             @AmeliaBt It sure is..                                              sure  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OS56PPZjg6kT"
      },
      "source": [
        "# # store processed data to a csv file\n",
        "# train_X.to_csv('gdrive/My Drive/Colab Notebooks/CleanedTrain.csv', index = True, header=True)\n",
        "# test_X.to_csv('gdrive/My Drive/Colab Notebooks/CleanedTest.csv', index = True, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdbg3VI4X2M_"
      },
      "source": [
        "### Tf-idf Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH2OoLFGX0n2"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidfVectorizer = TfidfVectorizer(max_df=0.99, min_df=1, stop_words='english', max_features=50)\n",
        "\n",
        "# apply tf-idf transformation to both train and test sets data\n",
        "tr_tfidf = tfidfVectorizer.fit_transform(train_X['processedText'])\n",
        "te_tfidf = tfidfVectorizer.transform(test_X['processedText'])\n",
        "\n",
        "# insert transformed data to numpy arrays for both training and test sets\n",
        "train_tfidf = tr_tfidf.toarray()\n",
        "test_tfidf = te_tfidf.toarray()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JW0sbRl3Wza"
      },
      "source": [
        "#### Convert input vectors to torch tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-s2GcdA13RV6"
      },
      "source": [
        "# covert numpy arrays to torch tensors\r\n",
        "train_tfidf, test_tfidf = map(torch.tensor, (train_tfidf, test_tfidf))\r\n",
        "# covert tensors data to float\r\n",
        "train_tfidf, test_tfidf = train_tfidf.float(), test_tfidf.float()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lu0tIeExpLPd"
      },
      "source": [
        "### GloVe Pre-trained Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L91p4LurpJ2Z"
      },
      "source": [
        "from torchtext.data import Field \n",
        "from torchtext.vocab import GloVe"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVGwqM_XFZIq"
      },
      "source": [
        "#### Load glove embeddings from disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K-_MSNUtNQI"
      },
      "source": [
        "with open('gdrive/My Drive/Colab Notebooks/train_glove.pkl', 'rb') as fp:\n",
        "    train_glove = pickle.load(fp)\n",
        "\n",
        "with open('gdrive/My Drive/Colab Notebooks/test_glove.pkl', 'rb') as fp:\n",
        "    test_glove = pickle.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rNqilsfHFCI"
      },
      "source": [
        "padding = train_X.processedText.map(lambda x: len(x)).max() # find the largest 'processedText' in dataframe to determine the padding's length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RITdTeFH3HIr"
      },
      "source": [
        "#### Convert input vectors to torch tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpCzi6Bo3HIx"
      },
      "source": [
        "#covert numpy arrays to torch tensors\n",
        "train_glove, test_glove = map(torch.tensor, (train_glove, test_glove))\n",
        "# covert tensors data to float\n",
        "train_glove, test_glove = train_glove.float(), test_glove.float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd2UmWYYd5PR"
      },
      "source": [
        "### Produce embedding input vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fFU56eQLAQ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6751e839-b381-47d2-d55e-16f3c8b32a8a"
      },
      "source": [
        "emb_size=50\r\n",
        "\r\n",
        "embedding = GloVe(name='6B', dim=emb_size) # use \"glove.6B.50d\" as embedding"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:52, 2.09MB/s]                           \n",
            "100%|█████████▉| 399838/400000 [00:10<00:00, 36397.69it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQJ02_a_3Mzv"
      },
      "source": [
        "# function to tokenize preprocessed text and add the necessary padding tokens \n",
        "def tokenize(df, padding):\n",
        "\n",
        "  text_field = Field(\n",
        "      sequential=True,\n",
        "      tokenize='spacy', \n",
        "      fix_length=padding,\n",
        "      lower=True\n",
        "  )\n",
        "\n",
        "  label_field = Field(sequential=False, use_vocab=False)\n",
        "\n",
        "  preprocessed_text = df['processedText'].apply(\n",
        "      lambda x: text_field.preprocess(x)\n",
        "  )\n",
        "\n",
        "  return preprocessed_text"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL932Qp2rW1K"
      },
      "source": [
        "# function that creates a mean vector for a series of tokens\n",
        "def tokens_to_vector(tokens, embedding, emb_size):\n",
        "  vectors = []\n",
        "  \n",
        "  for token in tokens:\n",
        "    try: \n",
        "        vectors.append(embedding[token].cpu().detach().numpy()) # add word's vector to list if word belongs to embedding dictionary\n",
        "    except KeyError:\n",
        "        vectors.append(np.zeros(emb_size).astype('float32') ) # else, add a zero vector to the list to represent unknown words\n",
        "          \n",
        "  total = np.zeros(emb_size).astype('float32') \n",
        "  \n",
        "  # compute the mean vector\n",
        "  for v in vectors: \n",
        "      total += v\n",
        "      \n",
        "  mean = total / len(vectors)\n",
        "\n",
        "  return mean.tolist() # return vector in list format"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOMAxNVQe0qw",
        "outputId": "3647b8c9-cdce-4b36-c6ae-0c5fe71c804a"
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (53.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cf3p3H3Y3E0Y"
      },
      "source": [
        "padding = train_X.processedText.map(lambda x: len(x)).max() # find the largest 'processedText' in dataframe to determine the padding's length"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKVv3EeVno2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69adf8c6-b9f4-41d7-ca27-757eff794036"
      },
      "source": [
        "# apply tokenization to both train and test sets\n",
        "train_toks = tokenize(train_X, padding)\n",
        "test_toks = tokenize(test_X, padding)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r100%|█████████▉| 399838/400000 [00:30<00:00, 36397.69it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Eqxp7EkBBOu"
      },
      "source": [
        "tr_glove = [] \n",
        "\n",
        "# create a list of vectors for every series of tokens in train set\n",
        "for i, tokens in enumerate(train_toks):\n",
        "  tr_glove.append(tokens_to_vector(tokens, embedding, emb_size))\n",
        "\n",
        "te_glove = []\n",
        "\n",
        "# create a list of vectors for every series of tokens in test set\n",
        "for i, tokens in enumerate(test_toks):\n",
        "  te_glove.append(tokens_to_vector(tokens, embedding, emb_size))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-e5AoOBFuSX"
      },
      "source": [
        "# convert list of vectors to numpy array\n",
        "train_glove = np.array(tr_glove)\n",
        "test_glove = np.array(te_glove)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBI4gRINLKpb"
      },
      "source": [
        "# # store glove embeddings to disk\n",
        "# with open('gdrive/My Drive/Colab Notebooks/train_glove.pkl', 'wb') as fp:\n",
        "#     pickle.dump(train_glove, fp)\n",
        "\n",
        "# with open('gdrive/My Drive/Colab Notebooks/test_glove.pkl', 'wb') as fp:\n",
        "#     pickle.dump(test_glove, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CLiNV0XfAde"
      },
      "source": [
        "#### Convert input vectors to torch tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR59A_DfrZXE"
      },
      "source": [
        "#covert numpy arrays to torch tensors\n",
        "train_glove, test_glove = map(torch.tensor, (train_glove, test_glove))\n",
        "# covert tensors data to float\n",
        "train_glove, test_glove = train_glove.float(), test_glove.float()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhSyXl904xb_"
      },
      "source": [
        "## Recurrent Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0KLu_hZeYKx"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3c0KOKtMziW"
      },
      "source": [
        "### Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvnVsVT6sjSI"
      },
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from d2l import torch as d2l\n",
        "\n",
        "# function that creates a dataframe to display the Precision, Recall and F1-score of the Neural Networks\n",
        "def display_metrics(model):\n",
        "  nn_dic = {model:['-','-','-']}\n",
        "  nn_df = pd.DataFrame.from_dict(nn_dic, orient='index', columns=['Precision','Recall','F1-Score'])\n",
        "\n",
        "  return nn_df\n",
        "\n",
        "# function to plot loss per epoch\n",
        "def loss_per_epoch(loss, title):\n",
        "  plt.figure(figsize=(8, 5))\n",
        "  plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "  plt.plot(range(len(loss)), loss)\n",
        "  plt.title('Loss - Epoch Diagram (' + title + ')', size=20)\n",
        "  plt.xlim=[1, len(loss)]\n",
        "  plt.xlabel('Epochs', size=20)\n",
        "\n",
        "  plt.yticks(loss, [i for i in loss])\n",
        "  plt.yscale('logit')\n",
        "  plt.ylabel('Loss', size=20)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        " \n",
        "# function that plots the ROC curve on the test set\n",
        "def roc_plot(net, test_X, test_y, batch_size, title):\n",
        "  fpr = dict()\n",
        "  tpr = dict()\n",
        "  roc_auc = dict()\n",
        "  test_iter = d2l.load_array((test_X, test_y), batch_size) # split train set in batches\n",
        "  \n",
        "  fin_y_pred = []\n",
        "  prec, rec, f1 = 0, 0, 0\n",
        "  for X, y in test_iter:\n",
        "    dim = X.shape[1]\n",
        "    X = X.unsqueeze(1)\n",
        "    X = X.expand(X.shape[0], dim, dim)\n",
        "    \n",
        "    # add parameters to device\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    y_pred = net.predict(X) # execute predict on test set\n",
        "    y_pred = torch.mean(y_pred, dim=1) # calculate mean\n",
        "    y_pred = y_pred.cpu().data.numpy() # convert to numpy\n",
        "\n",
        "    y = y.cpu().data.numpy() # convert to numpy \n",
        "\n",
        "    for i in range(2):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y, y_pred)\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "  plt.figure(figsize=(8, 5))\n",
        "  plt.style.use('seaborn-whitegrid')\n",
        "  plt.plot(fpr[1], tpr[1])\n",
        "\n",
        "  plt.title('Receiver operating characteristic (' + title + ')', size=20)\n",
        "  plt.xlabel('False Positive Rate', size=20)\n",
        "  plt.ylabel('True Positive Rate', size=20)\n",
        "  plt.show()\n",
        "  \n",
        "  roc_score = \"%.3f%%\" % (roc_auc[i] * 100)\n",
        "  print(\"\\nROC Score = \", roc_score)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir5xbfh2-RaN"
      },
      "source": [
        "### Bidirectional Stacked Recurrent Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKVUnt9E-RaN"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Bidirectional Stacked Recurrent Neural Net with LSTM /GRU cells\n",
        "\n",
        "    Structure:\n",
        "      Input, hidden and output layers\n",
        "      Number of layers > 1\n",
        "      Bidirectional=True\n",
        "    \n",
        "    Output layer:\n",
        "      Linear\n",
        "      Sigmoid activation function\n",
        "    \"\"\"\n",
        "    def __init__(self, cell_type, input_size, output_size, hidden_size=100, num_layers=1, dropout=0):\n",
        "        super(RNN, self).__init__()\n",
        "        \n",
        "        cells = {\n",
        "        \"RNN\" : nn.RNN,\n",
        "        \"LSTM\" : nn.LSTM,\n",
        "        \"GRU\" : nn.GRU\n",
        "        }\n",
        "\n",
        "        # class initializations\n",
        "        self.cell_type = cell_type\n",
        "        self.input_size = input_size \n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.rnn = cells[cell_type](         # RNN / LSTM / GRU model\n",
        "            input_size=input_size,           # input layer's size\n",
        "            hidden_size=hidden_size,         # hidden layer's size\n",
        "            num_layers=num_layers,           # number of layers \n",
        "            bidirectional=True,              # bidirectional RNN \n",
        "            batch_first=True,                # input's and output's first dimension has batch size\n",
        "            dropout=dropout                  # add dropout layer after rnn layer\n",
        "        )\n",
        "        \n",
        "        self.FC = nn.Linear(hidden_size * 2, output_size) # we need 2 extra layers as the output to the final layer because RNN is bidirectional\n",
        "            \n",
        "    def forward(self, x):\n",
        "        # LSTM cells return the last cell states\n",
        "        if self.cell_type == 'LSTM':\n",
        "            out, (last_hidden_state, last_cell_state) = self.rnn(x) \n",
        "        else:\n",
        "            out, last_hidden_state = self.rnn(x)\n",
        "            \n",
        "        output = self.FC(out)\n",
        "\n",
        "        return F.sigmoid(output) \n",
        "\n",
        "    def predict(self, x):\n",
        "        Y_pred = self.forward(x)\n",
        "        return Y_pred"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM6HJA6ZspsR"
      },
      "source": [
        "# function that trains a Neural Net and returns the loss history\n",
        "# with manual implementation of Early Stopping and BCELoss loss function\n",
        "def fit(net, train_X, train_y, epochs, learning_rate, batch_size, patience):\n",
        "  not_improved = 0\n",
        "  early_stop = False\n",
        "  min_ls = np.Inf # initialize minimum loss\n",
        "  \n",
        "  train_ls = []\n",
        "  train_iter = d2l.load_array((train_X, train_y), batch_size) # split train set in batches\n",
        "  \n",
        "  optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate) # Adam Optimizer\n",
        "  for epoch in range(epochs):\n",
        "    epoch_ls = 0\n",
        "    for X, y in train_iter:\n",
        "      criterion = nn.BCELoss() # use BCELoss to calucalate the loss\n",
        "\n",
        "      dim = X.shape[1]\n",
        "      X = X.unsqueeze(1) \n",
        "      X = X.expand(batch_size, dim, dim) # expand to 3D\n",
        "      net_x = torch.mean(net(X.float()), dim=1) # calculate mean\n",
        "\n",
        "      y = y.unsqueeze(1) \n",
        "\n",
        "      l = criterion(net_x, y) # calculate batch's loss\n",
        "      epoch_ls += l.item() # sum all batches' losses of current epoch\n",
        "      optimizer.zero_grad()\n",
        "      l.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "    \n",
        "    mean_ls = epoch_ls / len(train_iter) # calculate the mean loss of the current epoch\n",
        "    mean_ls = round(mean_ls, 6) # round up the loss to the 6th decimal digit\n",
        "\n",
        "    if mean_ls < min_ls: # store minimum loss\n",
        "      not_improved = 0\n",
        "      min_ls = mean_ls\n",
        "\n",
        "    else:\n",
        "      not_improved += 1 # raise not_improved counter\n",
        "\n",
        "    if (epoch + 1) >= patience and not_improved == patience: # apply early stopping \n",
        "      print(\"Early stopping! (patience = \" + str(patience) + \")\")\n",
        "      early_stop = True\n",
        "      break\n",
        "\n",
        "    print(f'epoch {epoch + 1}, loss {mean_ls:f}') \n",
        "    train_ls.append(mean_ls)\n",
        "\n",
        "  return train_ls\n",
        "\n",
        "# function that executes the Neural Net training and prints the loss per epoch, applying Early Stopping\n",
        "def train_net(device, net, train_X, train_y, sample, epochs=10, lr=0.1, batch=1, patience=3):\n",
        "  # add parameters to device\n",
        "  train_X = train_X.to(device)\n",
        "  train_y = train_y.to(device)\n",
        "  net.to(device)\n",
        "\n",
        "  # execute fit with Early Stopping on train set\n",
        "  train_ls = fit(net, train_X[:sample], train_y[:sample], epochs=epochs, learning_rate=lr, batch_size=batch, patience=patience) \n",
        "  print(f'\\nFinal loss {train_ls[-1]:f}')\n",
        "\n",
        "  return train_ls "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZu7Nyttmh6x"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# function that executes prediction on test set using sigmoid activation function on output layer\n",
        "def predict_on_test(device, net, test_X, test_y, batch_size=1):\n",
        "  test_iter = d2l.load_array((test_X, test_y), batch_size) # split train set in batches\n",
        "  \n",
        "  prec, rec, f1 = 0, 0, 0\n",
        "  for X, y in test_iter:\n",
        "    dim = X.shape[1]\n",
        "    X = X.unsqueeze(1)\n",
        "    X = X.expand(X.shape[0], dim, dim)\n",
        "    \n",
        "    # add parameters to device\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    y_pred = net.predict(X) # execute predict on test set\n",
        "    y_pred = torch.mean(y_pred, dim=1) # calculate mean\n",
        "    y_pred = y_pred.cpu().data.numpy() # convert to numpy\n",
        "\n",
        "    y_pred = np.where(y_pred >= 0.5, 1, 0) # if prediction is >= 0.5 set it to 1\n",
        "\n",
        "    y = y.cpu().data.numpy() # convert to numpy \n",
        "\n",
        "    p = metrics.precision_score(y, y_pred)\n",
        "    r = metrics.recall_score(y, y_pred)\n",
        "    f = metrics.f1_score(y, y_pred)\n",
        "\n",
        "    prec += p # sum all batches' precision\n",
        "    rec += r # sum all batches' recall\n",
        "    f1 += f # sum all batches' f1 score\n",
        "      \n",
        "  mean_prec = prec / len(test_iter) # calculate the mean precision of test set\n",
        "  mean_rec = rec / len(test_iter) # calculate the mean recall of test set\n",
        "  mean_f1 = f1 / len(test_iter) # calculate the mean f1 score of test set\n",
        "\n",
        "  final_prec = \"%.3f%%\" % (mean_prec * 100)\n",
        "  final_rec = \"%.3f%%\" % (mean_rec * 100)\n",
        "  final_f1 = \"%.3f%%\" % (mean_f1 * 100)\n",
        "\n",
        "  return final_prec, final_rec, final_f1"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0Dzsc_13Ch8"
      },
      "source": [
        "### Train & Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPZfeCWpwjdn",
        "outputId": "c4ccf07f-14ed-479f-e4c4-99949fecd1e1"
      },
      "source": [
        "# enable gpu for faster execution\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device available for running: \")\n",
        "print(device)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device available for running: \n",
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaouUOywTb8d"
      },
      "source": [
        "#### Tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5lFA-3TTn17"
      },
      "source": [
        "# initialize dataframe to display metrics\n",
        "tfidf_df = display_metrics('LSTM-TFIDF')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YSQNmDuTn18",
        "outputId": "fd5f7554-f59c-41a6-eff8-47db0d39117f"
      },
      "source": [
        "# initialize parameters\n",
        "lstm_cell = 'LSTM'                # model\n",
        "input_size = train_tfidf.shape[1] # number of input neurons\n",
        "output_size = 1                   # number of output neurons\n",
        "hidden_size = 2 * input_size      # number of hidden neurons\n",
        "num_layers = 2                    # number of stacked layers\n",
        "dropout = 0.2                     # dropout probability\n",
        "\n",
        "tfidf_net = RNN(lstm_cell, input_size, output_size, hidden_size, num_layers, dropout)\n",
        "print(tfidf_net)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN(\n",
            "  (rnn): LSTM(50, 100, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
            "  (FC): Linear(in_features=200, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBsuvBtYTn19",
        "outputId": "e86ecbf4-f4a8-40b9-a238-dabd950b6b6d"
      },
      "source": [
        "sample=train_tfidf.shape[0] # use the whole training set\n",
        "epochs=10                   # number of epochs\n",
        "lr=0.005                    # learning rate\n",
        "batch=1024                  # batch size\n",
        "patience=3                  # number of epochs, where loss doesn't improve\n",
        "\n",
        "# train Neural Net\n",
        "train_net(device, tfidf_net, train_tfidf, train_y, sample, epochs, lr, batch, patience) \n",
        "\n",
        "# predict on test set\n",
        "(tfidf_df.loc['LSTM-TFIDF','Precision'], \n",
        " tfidf_df.loc['LSTM-TFIDF','Recall'], \n",
        " tfidf_df.loc['LSTM-TFIDF','F1-Score']) = predict_on_test(device, tfidf_net, test_tfidf, test_y, batch) "
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1, loss 0.631548\n",
            "epoch 2, loss 0.629052\n",
            "epoch 3, loss 0.628191\n",
            "epoch 4, loss 0.627632\n",
            "epoch 5, loss 0.627326\n",
            "epoch 6, loss 0.626994\n",
            "epoch 7, loss 0.626656\n",
            "epoch 8, loss 0.626432\n",
            "epoch 9, loss 0.629573\n",
            "epoch 10, loss 0.633482\n",
            "\n",
            "Final loss 0.633482\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "hZ2GlmfMTn19",
        "outputId": "bcec0663-2105-493d-b43c-868256292208"
      },
      "source": [
        "tfidf_df"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LSTM-TFIDF</th>\n",
              "      <td>63.523%</td>\n",
              "      <td>50.613%</td>\n",
              "      <td>56.314%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Precision   Recall F1-Score\n",
              "LSTM-TFIDF   63.523%  50.613%  56.314%"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47MvXCMCBoO6"
      },
      "source": [
        "**In our first experiment, we implement a bidirectional stacked RNN model using tf-idf input vectors. This model is implemented based on parametres that are proven to be the most appropriate for our classification problem, after experimenting with our best bidirectional stacked RNN Neural Network with glove embeddings, which we will present later on. <br> We train all our RNN models with BCELoss loss function and we use sigmoid activation function (ideal for binary classification) in the output layer. Our best model is implemented using LSTM cells, dropout layers with 0.2 probability and the learning rate is 0.005. The number of hidden neurons is twice the number of input neurons and the number of stacked layers should normally be 3 for better results, but we set it to 2 for faster execution (We experiment with the number of stacked layers later). Moreover, aiming to avoid overfitting we train our RNNs with the Early Stopping technique, with patience=3. In our experiments we notice, that Early Stopping is indeed applied sooner or later depending on our model parametres. <br> Subsequently, we will explain thoroughly the reason why the above parametres are the best ones. Besides, the purpose of our first experiment is to prove the inability of tf-idf vectors to produce satisfying classification results. <br> Αfter conducting all our experiments with glove embeddings we observe that the above loss is worse by 0.1 or more compared to most experiments with glove RNN models. Furthermore, the prediction scores are very imbalanced and far worse than the glove RNNs ones. Therefore, there is no reason for further experementation with tf-idf input vectors.**\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56JssDknTOhi"
      },
      "source": [
        "#### GloVe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1c974bjZUzv"
      },
      "source": [
        "##### RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16Y9w4cWZp-a"
      },
      "source": [
        "# initialize dataframe to display metrics\n",
        "rnn_df = display_metrics('RNN-GLOVE')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7c8hUaFZp-a",
        "outputId": "2ea87fb0-8401-44b1-874e-b5b29b7cf58d"
      },
      "source": [
        "# initialize parameters\n",
        "rnn_cell = 'RNN'                  # model\n",
        "input_size = train_glove.shape[1] # number of input neurons\n",
        "output_size = 1                   # number of output neurons\n",
        "hidden_size = 2 * input_size      # number of hidden neurons\n",
        "num_layers = 2                    # number of stacked layers\n",
        "dropout = 0.2                     # dropout probability\n",
        "\n",
        "rnn_net = RNN(rnn_cell, input_size, output_size, hidden_size, num_layers, dropout)\n",
        "print(rnn_net)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN(\n",
            "  (rnn): RNN(50, 100, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
            "  (FC): Linear(in_features=200, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrXsBPyqZp-b",
        "outputId": "e6730b63-b585-488f-f01c-16ce37b12cd5"
      },
      "source": [
        "sample=train_glove.shape[0] # use the whole training set\n",
        "epochs=10                   # number of epochs\n",
        "lr=0.005                    # learning rate\n",
        "batch=1024                  # batch size\n",
        "patience=3                  # number of epochs, where loss doesn't improve\n",
        "\n",
        "# train Neural Net\n",
        "train_net(device, rnn_net, train_glove, train_y, sample, epochs, lr, batch, patience) \n",
        "\n",
        "# predict on test set\n",
        "(rnn_df.loc['RNN-GLOVE','Precision'], \n",
        " rnn_df.loc['RNN-GLOVE','Recall'], \n",
        " rnn_df.loc['RNN-GLOVE','F1-Score']) = predict_on_test(device, rnn_net, test_glove, test_y, batch) "
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1, loss 0.601485\n",
            "epoch 2, loss 0.595943\n",
            "epoch 3, loss 0.590860\n",
            "epoch 4, loss 0.587495\n",
            "epoch 5, loss 0.586926\n",
            "epoch 6, loss 0.583072\n",
            "epoch 7, loss 0.580005\n",
            "epoch 8, loss 0.610617\n",
            "epoch 9, loss 0.602646\n",
            "Early stopping! (patience = 3)\n",
            "\n",
            "Final loss 0.602646\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "lbPbRguAZp-c",
        "outputId": "4293ecf1-194d-49c6-aa62-539c9f7ce2b9"
      },
      "source": [
        "rnn_df"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>RNN-GLOVE</th>\n",
              "      <td>66.873%</td>\n",
              "      <td>71.564%</td>\n",
              "      <td>69.121%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Precision   Recall F1-Score\n",
              "RNN-GLOVE   66.873%  71.564%  69.121%"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ioL1sPuMt9h"
      },
      "source": [
        "**From our second experiment and afterwards, we implement RNN models using glove input vectors. Our concept is to keep the best parametres fixed and change just one parametre in each experiment. Our goal is to prove that the each parametre we change is not the best one for our classification problem. In our second experiment, we choose not to use LSTM or GRU cells. So we implement a RNN model with tanh non-linearity. We prefer tanh non-linearity over ReLu, because after conducting a small experiment, ReLu proved to produce terrible loss values and the model didn't converge. We also keep using 2 stacked layers instead of 3 for faster execution. <br> The positive outcome of our second experiment is that we achieve a big improvement in the prediction scores. Specifically, the scores are slightly more balanced and F1 Score has a rate that is close to the F1 Score of our best model. On the other hand, as we can see the loss values are still high compared to our following experiments and we observe that at the model begins to overfit as Early Stopping is applied. It's obvious that a model, which overfits is not reliable. Consequently, we should experiment with different cell types, in order to improve the loss convergence and eliminate the overfitting problem.**\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbdlylGudJeb"
      },
      "source": [
        "##### GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1j7hSRCdQeb"
      },
      "source": [
        "# initialize dataframe to display metrics\n",
        "gru_df = display_metrics('GRU-GLOVE')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAAnEgTjdQep",
        "outputId": "b8679c70-696e-4ffd-c3d4-f6c2a01abd6f"
      },
      "source": [
        "# initialize parameters\n",
        "gru_cell = 'GRU'                  # model\n",
        "input_size = train_glove.shape[1] # number of input neurons\n",
        "output_size = 1                   # number of output neurons\n",
        "hidden_size = 2 * input_size      # number of hidden neurons\n",
        "num_layers = 2                    # number of stacked layers\n",
        "dropout = 0.2                     # dropout probability\n",
        "\n",
        "gru_net = RNN(gru_cell, input_size, output_size, hidden_size, num_layers, dropout)\n",
        "print(gru_net)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN(\n",
            "  (rnn): GRU(50, 100, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
            "  (FC): Linear(in_features=200, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stbSwAsRdQeq",
        "outputId": "d0ab891e-eb37-4976-a7e9-466f8d03874a"
      },
      "source": [
        "sample=train_glove.shape[0] # use the whole training set\n",
        "epochs=10                   # number of epochs\n",
        "lr=0.005                    # learning rate\n",
        "batch=1024                  # batch size\n",
        "patience=3                  # number of epochs, where loss doesn't improve\n",
        "\n",
        "# train Neural Net\n",
        "train_net(device, gru_net, train_glove, train_y, sample, epochs, lr, batch, patience) \n",
        "\n",
        "# predict on test set\n",
        "(gru_df.loc['GRU-GLOVE','Precision'], \n",
        " gru_df.loc['GRU-GLOVE','Recall'], \n",
        " gru_df.loc['GRU-GLOVE','F1-Score']) = predict_on_test(device, gru_net, test_glove, test_y, batch) "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1, loss 0.580139\n",
            "epoch 2, loss 0.556862\n",
            "epoch 3, loss 0.547185\n",
            "epoch 4, loss 0.539554\n",
            "epoch 5, loss 0.535844\n",
            "epoch 6, loss 0.535861\n",
            "epoch 7, loss 0.534980\n",
            "epoch 8, loss 0.530525\n",
            "epoch 9, loss 0.534642\n",
            "epoch 10, loss 0.535554\n",
            "\n",
            "Final loss 0.535554\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "xC_m0wNVdQer",
        "outputId": "2d1a1c15-457e-463b-8d9d-a1293e646a4e"
      },
      "source": [
        "gru_df"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>GRU-GLOVE</th>\n",
              "      <td>69.365%</td>\n",
              "      <td>73.252%</td>\n",
              "      <td>71.237%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Precision   Recall F1-Score\n",
              "GRU-GLOVE   69.365%  73.252%  71.237%"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIQe2KE4YrFc"
      },
      "source": [
        "**In our third experiment, we aim to eliminate overfitting and reduce the loss by using GRU cells. <br> From the beginning of the training we are lucky to observe a small loss reduction by 0.02 compared to our previous model. We also note that the prediction scores are significantly better than the scores produced by our previous model. Yet, the model begins to overfit once again. The Early Stopping technique is sooner or later applied, depending on the moment that overfitting begins. Therefore, our new model doesn't help us accomplish our initial goal and we are in fact obligated to experiment with the only cell type left, the LSTM.**\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7JZeu2FlcIp"
      },
      "source": [
        "##### LSTM - Learning Rate Effect"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-XtAch3lcI3"
      },
      "source": [
        "# initialize dataframe to display metrics\n",
        "lstmLR_df = display_metrics('LSTM-GLOVE-LR')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8U_WTvTWlcI4",
        "outputId": "47863fdf-9caa-4dca-a2e0-3248a9b7fbf6"
      },
      "source": [
        "# initialize parameters\n",
        "lstm_cell = 'LSTM'                # model\n",
        "input_size = train_glove.shape[1] # number of input neurons\n",
        "output_size = 1                   # number of output neurons\n",
        "hidden_size = 2 * input_size      # number of hidden neurons\n",
        "num_layers = 2                    # number of stacked layers\n",
        "dropout = 0.2                     # dropout probability\n",
        "\n",
        "lstmLR_net = RNN(lstm_cell, input_size, output_size, hidden_size, num_layers, dropout)\n",
        "print(lstmLR_net)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN(\n",
            "  (rnn): LSTM(50, 100, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
            "  (FC): Linear(in_features=200, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSHEHLJblcI6",
        "outputId": "c8a0e4d3-9d2c-4c1d-f5e8-8e06ef366b50"
      },
      "source": [
        "sample=train_glove.shape[0] # use the whole training set\n",
        "epochs=10                   # number of epochs\n",
        "lr=0.01                     # learning rate\n",
        "batch=1024                  # batch size\n",
        "patience=3                  # number of epochs, where loss doesn't improve\n",
        "\n",
        "# train Neural Net\n",
        "train_net(device, lstmLR_net, train_glove, train_y, sample, epochs, lr, batch, patience) \n",
        "\n",
        "# predict on test set\n",
        "(lstmLR_df.loc['LSTM-GLOVE-LR','Precision'], \n",
        " lstmLR_df.loc['LSTM-GLOVE-LR','Recall'], \n",
        " lstmLR_df.loc['LSTM-GLOVE-LR','F1-Score']) = predict_on_test(device, lstmLR_net, test_glove, test_y, batch) "
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1, loss 0.577590\n",
            "epoch 2, loss 0.555778\n",
            "epoch 3, loss 0.547897\n",
            "epoch 4, loss 0.542875\n",
            "epoch 5, loss 0.563727\n",
            "epoch 6, loss 0.601713\n",
            "Early stopping! (patience = 3)\n",
            "\n",
            "Final loss 0.601713\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "7AN1Ga9elcI7",
        "outputId": "7a4738c9-d55d-43bf-ebba-012d50a1de0f"
      },
      "source": [
        "lstmLR_df"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LSTM-GLOVE-LR</th>\n",
              "      <td>67.505%</td>\n",
              "      <td>67.383%</td>\n",
              "      <td>67.425%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Precision   Recall F1-Score\n",
              "LSTM-GLOVE-LR   67.505%  67.383%  67.425%"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4O-2G9bgWWJ"
      },
      "source": [
        "**From our fourth experiment and afterwards, we implement RNN Neural Networks using LSTM cells, as LSTM is gradually proven to be the ideal cell type for our classification problem. So we keep experimenting with the remaining parametres. <br> In our fourth experiment, we try to show the importance of the learning rate and the big effect it can have to a model's convergence. That's why we change the learning rate from 0.05 to 0.01, which theoretically shouldn't make a significant difference. At first sight, the model seems to converge fine, but it doesn't take long to realise that our model begins once again to overfit as Early Stopping is applied. Concerning the prediction scores, they seem balanced but they are worse than the previous onces.**\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIDpo514e7aL"
      },
      "source": [
        "##### LSTM - 3 Stacked Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Szwersrve7aO"
      },
      "source": [
        "# initialize dataframe to display metrics\n",
        "lstm3_df = display_metrics('LSTM-GLOVE-3')"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFC1GwW3e7aP",
        "outputId": "ef7ff494-4080-4857-a018-f50d988b8582"
      },
      "source": [
        "# initialize parameters\n",
        "lstm_cell = 'LSTM'                # model\n",
        "input_size = train_glove.shape[1] # number of input neurons\n",
        "output_size = 1                   # number of output neurons\n",
        "hidden_size = 2 * input_size      # number of hidden neurons\n",
        "num_layers = 3                    # number of stacked layers\n",
        "dropout = 0.2                     # dropout probability\n",
        "\n",
        "lstm3_net = RNN(lstm_cell, input_size, output_size, hidden_size, num_layers, dropout)\n",
        "print(lstm3_net)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN(\n",
            "  (rnn): LSTM(50, 100, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n",
            "  (FC): Linear(in_features=200, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PPuv3Sne7aP",
        "outputId": "52868291-734d-4e91-9ec3-6fb6a48eb89b"
      },
      "source": [
        "sample=train_glove.shape[0] # use the whole training set\n",
        "epochs=10                   # number of epochs\n",
        "lr=0.005                    # learning rate\n",
        "batch=1024                  # batch size\n",
        "patience=3                  # number of epochs, where loss doesn't improve\n",
        "\n",
        "# train Neural Net\n",
        "train_net(device, lstm3_net, train_glove, train_y, sample, epochs, lr, batch, patience) \n",
        "\n",
        "# predict on test set\n",
        "(lstm3_df.loc['LSTM-GLOVE-3','Precision'], \n",
        " lstm3_df.loc['LSTM-GLOVE-3','Recall'], \n",
        " lstm3_df.loc['LSTM-GLOVE-3','F1-Score']) = predict_on_test(device, lstm3_net, test_glove, test_y, batch) "
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1, loss 0.576224\n",
            "epoch 2, loss 0.555022\n",
            "epoch 3, loss 0.546569\n",
            "epoch 4, loss 0.540741\n",
            "epoch 5, loss 0.536076\n",
            "epoch 6, loss 0.532324\n",
            "epoch 7, loss 0.528786\n",
            "epoch 8, loss 0.527463\n",
            "epoch 9, loss 0.525237\n",
            "epoch 10, loss 0.522132\n",
            "\n",
            "Final loss 0.522132\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "xnTBh6MTe7aQ",
        "outputId": "6ecda554-fd35-491d-b179-57d76dcd27db"
      },
      "source": [
        "lstm3_df"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LSTM-GLOVE-3</th>\n",
              "      <td>73.808%</td>\n",
              "      <td>67.553%</td>\n",
              "      <td>70.520%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Precision   Recall F1-Score\n",
              "LSTM-GLOVE-3   73.808%  67.553%  70.520%"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHVO5HZ78oVQ"
      },
      "source": [
        "**As we mentioned before we have trained all our RNN models with BCELoss loss function and we have used sigmoid activation function in the output layer. We also montioned that the best model is implemented using LSTM cells, dropout layers with 0.2 probability and the learning rate is 0.005. The number of hidden neurons is twice the number of input neurons and the number of stacked layers is 3. As we can see in our current, fifth experiment, our model contains all the above parametres and it is, typically, the most effective model of all in terms of loss convergence and prodiction scores, but in fact not the most useful one (best). We observe that thanks to the LSTM cells and the 3 stacked layers our model is converging faster than ever, manages to avoid overfitting and after all produces the best scores on the prediction set. Actually, we implemented a similar model with 4 stacked layers that produced slightly better results and one with 2 stacked layers that produced slightly worse results. We present the latter right below. The reason why we later on prefer to set the 2 stacked bidirectional RNN as our best model is the negligible difference compared to the 3 and 4 stacked RNNs both in loss convergence as in prediction scores combined with the significantly faster execution time of the 2 stacked RNN. In a few words as we will see below the 2 stacked bidirectional RNN is equally efficient and much faster than the 3 stacked bidirectional RNN.**\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAUMmSm7gf0v"
      },
      "source": [
        "##### LSTM - Best Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqGlRs5_53PW"
      },
      "source": [
        "# initialize dataframe to display metrics\n",
        "best_df = display_metrics('LSTM-GLOVE-BEST')"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql7_Ph-gTOhi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ac4c528-3c6e-4435-cae0-6f94ec56e99c"
      },
      "source": [
        "# initialize parameters\n",
        "lstm_cell = 'LSTM'                # model\n",
        "input_size = train_glove.shape[1] # number of input neurons\n",
        "output_size = 1                   # number of output neurons\n",
        "hidden_size = 2 * input_size      # number of hidden neurons\n",
        "num_layers = 2                    # number of stacked layers\n",
        "dropout = 0.2                     # dropout probability\n",
        "\n",
        "best_net = RNN(lstm_cell, input_size, output_size, hidden_size, num_layers, dropout)\n",
        "print(best_net)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN(\n",
            "  (rnn): LSTM(50, 100, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
            "  (FC): Linear(in_features=200, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShzF80JgTOhi",
        "outputId": "6ec893c0-2c72-463b-cbba-3754ec9444e9"
      },
      "source": [
        "sample=train_glove.shape[0] # use the whole training set\n",
        "epochs=20                   # number of epochs\n",
        "lr=0.005                    # learning rate\n",
        "batch=2048                  # batch size\n",
        "patience=3                  # number of epochs, where loss doesn't improve\n",
        "\n",
        "# train Neural Net\n",
        "glove_ls = train_net(device, best_net, train_glove, train_y, sample, epochs, lr, batch, patience) \n",
        "\n",
        "# predict on test set\n",
        "(best_df.loc['LSTM-GLOVE-BEST','Precision'], \n",
        " best_df.loc['LSTM-GLOVE-BEST','Recall'], \n",
        " best_df.loc['LSTM-GLOVE-BEST','F1-Score']) = predict_on_test(device, best_net, test_glove, test_y, batch) "
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1, loss 0.578249\n",
            "epoch 2, loss 0.556724\n",
            "epoch 3, loss 0.548151\n",
            "epoch 4, loss 0.542525\n",
            "epoch 5, loss 0.537649\n",
            "epoch 6, loss 0.534102\n",
            "epoch 7, loss 0.530894\n",
            "epoch 8, loss 0.528769\n",
            "epoch 9, loss 0.525330\n",
            "epoch 10, loss 0.521799\n",
            "epoch 11, loss 0.518954\n",
            "epoch 12, loss 0.516601\n",
            "epoch 13, loss 0.513377\n",
            "epoch 14, loss 0.512035\n",
            "epoch 15, loss 0.509824\n",
            "epoch 16, loss 0.506401\n",
            "epoch 17, loss 0.502483\n",
            "epoch 18, loss 0.500309\n",
            "epoch 19, loss 0.497796\n",
            "epoch 20, loss 0.494170\n",
            "\n",
            "Final loss 0.494170\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob2VtbJyP8hP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "efc560f0-bc1f-4b83-e3f0-6fe74fdd724d"
      },
      "source": [
        "best_df"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LSTM-GLOVE-BEST</th>\n",
              "      <td>71.716%</td>\n",
              "      <td>71.919%</td>\n",
              "      <td>71.806%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Precision   Recall F1-Score\n",
              "LSTM-GLOVE-BEST   71.716%  71.919%  71.806%"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvBkLhcJ7syZ"
      },
      "source": [
        "**In our current, sixth experiment, we present our best model, which, as we mentioned, contains 2 stacked LSTM layers and the rest, best parametres that we showed above. We can see that our tellings are verified as our model's loss values are almost the same as the values of our previous 2 stacked RNN model (until epoch 10) and the scores on the prediction set are almost the same as well. The big advantage of our current-best model compared to our previous model is the much faster training execution. This is of course expected because of the smaller number of stacked layers used. The fast loss convergence is also verified when we train our model with 20 epochs as we observe for the first time the loss obtaining a value below 0.5 . <br><br>\n",
        "After having chosen our best model we experimented with some other parametres as well and we tried to explain the reason why these parametres are the ones that produce the best eperimental results. First of all, from our experiments we can draw the conclusion that in our classification problem LSTM Networks perform better than GRU Networks and much better than standard RNN Networks. We know that in theory it is difficult to train standard RNNs to solve problems that require learning long-term temporal dependencies. This is because the gradient of the loss function decays exponentially with time (vanishing gradient problem). It is a fact that a Sentiment Classification problem like ours is composed of plenty long-term temporal dependencies that determine the variability of a sentiment. So LSTMs' memory cells help to maintain information in memory for long periods of time. GRUs are similar to LSTMs, but use a simplified structure. Their structure is useful for faster training execution and better performance on small datasets. Yet, as we showed earlier our GRU model begins to overfit on our large dataset, that consists of many long-term temporal dependencies. <br> Moreover, we experimented with the gradient clipping technique and different dropout probabilities. The use of gradient clipping technique slowed down the training execution and led to a very slow loss convergence. Therefore, we didn't include it in our implementation. Finally, the dropout layers helped us reduce and sometimes fully eliminate the overfitting problem. Except from the above models, tha use 0.2 dropout probability, we also trained a model with 0.5 dropout probability, but the results were worse in both loss value and prediction accuracy terms.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3zpMtck8I6J"
      },
      "source": [
        "### Loss - Epoch Diagram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W09LurEPfcw1"
      },
      "source": [
        "**In the below Loss - Epoch Diagram we visualise the loss convergence of our best model epoch by epoch. It is obvious, that our best model <br> (2 stacked, bidirection LSTM) is converging fast and smoothly and it does not overfit.**\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEhg5lfOTOhj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "66c575a4-e820-4fca-d290-83b7aa6eee82"
      },
      "source": [
        "loss_per_epoch(glove_ls, 'LSTM-GLOVE-BEST')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1of_QkvmF7Rr"
      },
      "source": [
        "### ROC Curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn55nlXEoipb"
      },
      "source": [
        "**The Auc Score of LSTM-GLOVE-BEST Neural Network, using pre-trained glove embeddings input vectors is ~80% and it's a decent score. As a matter of fact, the Auc Score is almost the same for all the models we experimented with. The high Auc Score means that the model has a good ability at measuring how often a sentiment rating is correct. We should be happy with our result, specially if we consider that Recurrent Neural Networks is a class of Neural Networks that are helpful in modeling sequencial data and they are not so effective at extracting local and position-invariant features. For tasks like Sentiment Analysis, where feature detection in text is more important (searching for angry terms, irony, sadness etc.), a Convolution Neural Network would produce the best results possible. <br> The Auc Score is visualized in the below ROC diagram, where the outcome is almost a perfect curve.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "0-ZqQmixF7gn",
        "outputId": "7f34ad5b-7457-4824-d30b-46459d85229a"
      },
      "source": [
        "# display the best ROC diagram based on Auc Score\n",
        "roc_plot(best_net, test_glove, test_y, batch, 'LSTM-GLOVE-BEST')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ROC Score =  79.698%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk3bBsfYGURV"
      },
      "source": [
        "### Recurrent Neural Network vs Feed-Forward Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "EAUW__llZTpE",
        "outputId": "4778ae38-fee0-4ab9-8808-87a12641db9b"
      },
      "source": [
        "# initialize dataframe to display loss results \r\n",
        "ls_dic = {'FFNN-GLOVE':['-'], 'LSTM-GLOVE-BEST':['-']}\r\n",
        "ls_df = pd.DataFrame.from_dict(ls_dic, orient='index', columns=['Final-loss'])\r\n",
        "\r\n",
        "ls_df.loc['FFNN-GLOVE', 'Final-loss'] = '0.518319'\r\n",
        "ls_df.loc['LSTM-GLOVE-BEST', 'Final-loss'] = glove_ls[-1]\r\n",
        "ls_df"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Final-loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>FFNN-GLOVE</th>\n",
              "      <td>0.518319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LSTM-GLOVE-BEST</th>\n",
              "      <td>0.49417</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Final-loss\n",
              "FFNN-GLOVE        0.518319\n",
              "LSTM-GLOVE-BEST    0.49417"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guvFIocGjWoi"
      },
      "source": [
        "**We observe that both Neural Networks produce better results when using pre-trained glove embeddings input vectors. Firstly, we compare our best Recurrent Neural Network with our best Feed-Forward Neural Network of our first notebook, based on the loss convergence. We train our best models with 20 epochs in both cases and we notice that our bidirectional 2 stacked RNN model, using LSTM cells is converging faster than our best Feed-Forward Neural Network. That's a logical outcome, because as we mentioned earlier LSTMs are consisted of memory cells that are able to maintain information in memory for long periods of time.\r\n",
        "On the other hand, Feed-Foward Neural Networks are primarily used in cases where the data to be learned is neither sequential nor time-dependent. As a result, in a Sentiment Classification problem like ours, which is composed of plenty long-term temporal dependencies we expect our RNN to learn the data faster.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "1yT4Fj89Yoj3",
        "outputId": "cc2a9860-9777-405d-8997-e14962d5fba8"
      },
      "source": [
        "# initialize dataframe to display metrics results \r\n",
        "sc_dic = {'FFNN-GLOVE':['-', '-', '-'], 'LSTM-GLOVE-BEST':['-', '-', '-']}\r\n",
        "sc_df = pd.DataFrame.from_dict(sc_dic, orient='index', columns=['Precision', 'Recall', 'F1-Score'])\r\n",
        "\r\n",
        "sc_df.loc['FFNN-GLOVE','Precision'] = '73.868%'\r\n",
        "sc_df.loc['FFNN-GLOVE','Recall'] = '73.475%'\r\n",
        "sc_df.loc['FFNN-GLOVE','F1-Score'] = '73.671%'\r\n",
        "\r\n",
        "sc_df.loc['LSTM-GLOVE-BEST','Precision'] = best_df.loc['LSTM-GLOVE-BEST','Precision']\r\n",
        "sc_df.loc['LSTM-GLOVE-BEST','Recall'] = best_df.loc['LSTM-GLOVE-BEST','Recall']\r\n",
        "sc_df.loc['LSTM-GLOVE-BEST','F1-Score'] = best_df.loc['LSTM-GLOVE-BEST','F1-Score']\r\n",
        "\r\n",
        "sc_df "
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>FFNN-GLOVE</th>\n",
              "      <td>73.868%</td>\n",
              "      <td>73.475%</td>\n",
              "      <td>73.671%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LSTM-GLOVE-BEST</th>\n",
              "      <td>71.716%</td>\n",
              "      <td>71.919%</td>\n",
              "      <td>71.806%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Precision   Recall F1-Score\n",
              "FFNN-GLOVE        73.868%  73.475%  73.671%\n",
              "LSTM-GLOVE-BEST   71.716%  71.919%  71.806%"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGbQFN73GKjc"
      },
      "source": [
        "**Subsequently, we compare our best models, based on the metrics of the prediction on the test set. Both models seem to produce very similar metrics with our FFNN being slightly more effective than our RNN, assuming that the F1-Score is a descent representative for a model's effeciency. Even though the metrics difference is not significant we can notice that the LSTM's ability on maintaining information leads to a faster convergence but not to better classification results. Yet, as we mentioned the metrics difference is insignificant. As a result, the noticeable faster convergence of RNN (RNN model converges even faster than FFNN if we train them with more epochs) is an important factor that can lead to its supremacy compared to FFNN. Either way, neither Recurrent Neural Networks nor Feed-Forward Neural Networks are the ideal to be applied in feature detection in texts. As we know, in theory, for tasks like Sentiment Analysis, where feature detection in text is more important (searching for angry terms, irony, sadness etc.), a Convolution Neural Network would surely produce better results.**"
      ]
    }
  ]
}